# Architecture

## About the Project

This project is a comprehensive microservices platform developed to showcase Python auto-instrumentation with OpenTelemetry. It features:

- **Business Application**: Complete order and stock management system for a wood supply business
- **Observability Stack**: Full Grafana stack (Loki, Mimir, Tempo) with OpenTelemetry auto-instrumentation
- **AI-Powered Analysis**: Intelligent agentic network for natural language observability queries
- **Modern Python Stack**: Python 3.14, UV package manager, FastAPI, Pydantic
- **Production-Ready Patterns**: Docker-first, configurable, with error simulation for testing

This is not just a demo - it's a complete reference implementation demonstrating modern observability best practices.

## Microservices

The application consists of the following microservices:

- **customer** ğŸªµ - Kafka producer acting as a client for ordering wood
- **supplier** ğŸªµ - Kafka producer acting as a supplier to replenish stock
- **ordercheck** ğŸ“¦ - Kafka consumer serving as the order reception service
- **suppliercheck** ğŸ“Š - Kafka consumer managing stock levels
- **stock** ğŸ—ï¸ - Stock management API
- **order** ğŸ“ - Order management API
- **ordermanagement** ğŸ˜„ - Service for updating order status

## Infrastructure Components

The complete application is containerized. The `docker-compose.yml` file builds all microservices and deploys the following components:

- **Kafka** ğŸ“¨ - Cluster to receive orders and stock updates
- **PostgreSQL** ğŸ—„ï¸ - Relational database
- **Adminer** ğŸ“‚ - Web interface for database visualization
- **Grafana** ğŸ“Š - Standard visualization tool
- **Grafana with MCP support** ğŸ¤– - Enhanced Grafana with Model Context Protocol for AI integration
- **Loki** ğŸ“ - Log database
- **Mimir** ğŸ“ˆ - Metrics database
- **Tempo** ğŸ“ - Traces database
- **Otel Gateway** ğŸ› ï¸ - API for receiving observability data

## Project Structure

```
python-otel-project-demo/
â”œâ”€â”€ common-models/                # Shared business models (for all business services)
â”‚   â”œâ”€â”€ common_models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ models.py            # Business models (WoodType, Order, Stock, OrderTracking)
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ common-ai/                    # Shared AI utilities (for AI agents only)
â”‚   â”œâ”€â”€ common_ai/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent_models.py      # Agent models (AgentRequest, AgentResponse, AgentType)
â”‚   â”‚   â”œâ”€â”€ mcp_client.py        # MCP client for Grafana datasources
â”‚   â”‚   â””â”€â”€ llm_config.py        # LLM configuration helper
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ customer/                     # Microservice: Kafka producer (customer orders)
â”œâ”€â”€ order/                        # Microservice: Order management API
â”œâ”€â”€ stock/                        # Microservice: Stock management API
â”œâ”€â”€ supplier/                     # Microservice: Kafka producer (supplier)
â”œâ”€â”€ ordercheck/                   # Microservice: Kafka consumer (order processing)
â”œâ”€â”€ suppliercheck/                # Microservice: Kafka consumer (stock updates)
â”œâ”€â”€ ordermanagement/              # Microservice: Order status updates
â”œâ”€â”€ agent-orchestrator/           # AI Agent: Main coordinator
â”œâ”€â”€ agent-logs/                   # AI Agent: Loki log analysis
â”œâ”€â”€ agent-metrics/                # AI Agent: Mimir metrics analysis
â”œâ”€â”€ agent-traces/                 # AI Agent: Tempo traces analysis
â”œâ”€â”€ agents-ui/                    # Web UI for agents
â”œâ”€â”€ docs/                         # Documentation
â””â”€â”€ docker-compose.yml            # Complete stack orchestration
```

### Shared Modules

**common-models/** - Business domain models shared across microservices:
- Used by: `order`, `stock`, `customer`, `supplier`, `ordercheck`, `suppliercheck`, `ordermanagement`
- Contains: `WoodType`, `OrderStatus`, `Stock`, `Order`, `OrderTracking`
- Dependencies: Only `pydantic` (lightweight)

**common-ai/** - AI utilities for intelligent agents:
- Used by: `agent-orchestrator`, `agent-logs`, `agent-metrics`, `agent-traces`
- Contains: MCP client, LLM config, agent models
- Dependencies: `httpx`, `langchain`, `langchain-openai`, `pydantic`

## Technology Stack

- **Python 3.14+** - Latest stable Python version
- **UV** - Fast Python package manager and resolver
- **FastAPI** - Modern web framework for REST APIs
- **Pydantic** - Data validation using Python type annotations
- **OpenTelemetry** - Observability instrumentation
- **LangChain** - Framework for LLM applications (agents only)
- **Kafka** - Message streaming platform
- **PostgreSQL** - Relational database
- **Grafana Stack** - Loki (logs), Mimir (metrics), Tempo (traces)

## Error Simulation

ğŸ­ The application includes built-in error simulation for testing observability:

- **Customer Service** - Simulates Kafka/network failures when sending orders
- **Supplier Check Service** - Simulates API/network failures when processing stock updates
- **Configurable Error Rate** - Set `ERROR_RATE` environment variable (default: 0.1 = 10%)

Example configuration:

```bash
# In docker-compose.yml or your environment
ERROR_RATE=0.2  # 20% error rate for testing
```
