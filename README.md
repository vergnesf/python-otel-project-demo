# Python Otel ğŸ

## What is this project? ğŸ˜²

This project is a set of microservices developed by a non-python-developer that allows you to view and understand Python auto-instrumentation with OpenTelemetry.

## How does it work? ğŸ¤”

The application is structured as follows:

- **customer**: Kafka producer that acts as the client for ordering wood ğŸªµ
- **supplier**: Kafka producer that acts as the supplier to replenish the wood stock ğŸªµ
- **customercheck**: Kafka consumer that serves as the order reception service ğŸ“¦
- **suppliercheck**: Kafka consumer that manages stock levels ğŸ“Š
- **stock**: API for managing stock ğŸ—ï¸
- **order**: API for managing orders ğŸ“
- **ordermanagement**: A service that updates the order status ğŸ˜„

The entire application is containerized, and the `docker-compose` file will build all the microservices and deploy the following additional components:

- **Kafka**: A cluster to receive orders and stock updates ğŸ“¨
- **PostgreSQL**: PostgreSQL database ğŸ—„ï¸
- **Adminer**: Web tool for viewing your database ğŸ“‚
- **Grafana**: Visualization tool ğŸ“Š
- **Loki**: Log database ğŸ“
- **Mimir**: Metrics database ğŸ“ˆ
- **Tempo**: Traces database ğŸ“
- **Otel Gateway**: API for receiving observability data ğŸ› ï¸

To run everything, use:

```sh
docker compose up -d --build
```

### Useful URLs ğŸŒ

- [Grafana](http://localhost:3000/) ğŸ“Š
- [AKHQ](http://localhost:8080/) ğŸ› ï¸
- [Adminer](http://localhost:8081/) ğŸ—ƒï¸

## Running Locally ğŸ›

Each microservice is set up with **uv**, so you can launch the different services using `uv run`.

Locally, you'll need to modify `PYTHONPATH` to include the project and access the "common" part, which simplifies things for me.

To run a microservice with auto-instrumentation:

```sh
uv run opentelemetry-instrument \
    --traces_exporter otlp \
    --metrics_exporter otlp \
    --service_name customer2 \
    --exporter_otlp_endpoint http://localhost:4318 \
    --log_level debug \
    python -m order.main
```

## Kubernetes Section âš“

Integrating Kubernetes into this project enables efficient deployment and orchestration of microservices. Here are the steps to set up a local test environment using **kind** (Kubernetes IN Docker) ğŸ³ and to deploy a highly available PostgreSQL database with **CloudNativePG** ğŸ˜.

### Creating a Kubernetes Cluster with kind ğŸ”¨

**kind** is a tool that lets you create local Kubernetes clusters using Docker as the container runtime. Itâ€™s perfect for quickly testing deployments in a simple environment. âš¡

```sh
kind create cluster -n test-cluster
```

### Deploying CloudNativePG ğŸ˜

**CloudNativePG** is a solution that simplifies managing PostgreSQL databases in a Kubernetes environment, providing high availability features. ğŸš€ This sets up the necessary resources to run PostgreSQL reliably and efficiently. ğŸ›¡ï¸

```sh
kubectl apply --server-side -f https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/release-1.24/releases/cnpg-1.24.1.yaml
```

### Deploy it ğŸš€

```sh
cd k8s/base
k apply -k .
```