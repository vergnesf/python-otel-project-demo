# Supplier Service

> **Status:** `KEEPER` â€” Stable service. Expected to stay functional and tested.

Kafka producer that simulates supplier stock updates being sent to the system.

## Why I built this

To learn how to structure multiple symmetric Kafka producers sharing a model library,
and how keeping services symmetric makes observability comparison in Grafana much easier.

## ðŸ“‹ Overview

- **Type**: Kafka Producer
- **Topic**: `stocks`
- **Frequency**: Configurable interval (60s in code, 5s in docker-compose)
- **Error Simulation**: Configurable error rate (default: 10%)
- **Dependencies**: Kafka broker, common-models

## ðŸš€ Running the Service

```bash
# With Docker (recommended)
docker-compose up supplier

# Local development
cd supplier/ && uv sync
uv run python -m supplier.supplier_producer
```

## ðŸ”§ Configuration

```bash
KAFKA_BOOTSTRAP_SERVERS=broker:29092
INTERVAL_SECONDS=60     # How often to send stock updates (seconds)
ERROR_RATE=0.1          # Fraction of updates that will fail (0.0â€“1.0)
LOG_LEVEL=INFO
OTEL_SERVICE_NAME=supplier
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
```

## ðŸ“Š What it generates

Random stock updates with wood types (oak, maple, birch, elm, pine) and quantities (1â€“100 units).
Randomly fails at `ERROR_RATE` to produce noisy, realistic telemetry.

## ðŸ”„ Integration

Publishes to â†’ `stocks` Kafka topic â†’ consumed by `suppliercheck`

## ðŸ“ˆ Observability

Auto-instrumented via `opentelemetry-instrument`. Logs â†’ Loki, Metrics â†’ Mimir, Traces â†’ Tempo.

## ðŸ§ª Testing

```bash
uv run pytest
uv run pytest --cov=supplier --cov-report=html
```
